{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Classification Using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(path):\n",
    "    splits = ['train', 'val', 'test']\n",
    "    data = {'train': [], 'val': [], 'test': []}\n",
    "    labels = {'train': [], 'val': [], 'test': []}\n",
    "    for split in splits:\n",
    "        split_path = os.path.join(path, split)\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if (int(label) == 0):\n",
    "                cur_label = 0\n",
    "            else:\n",
    "                cur_label = len(label)\n",
    "            if os.path.isdir(label_path):\n",
    "                for image_name in os.listdir(label_path):\n",
    "                    image_path = os.path.join(label_path, image_name)\n",
    "                    try:\n",
    "                        image = Image.open(image_path).convert('L')\n",
    "                        image_array = np.array(image)\n",
    "                        data[split].append(image_array)\n",
    "                        labels[split].append(cur_label)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {image_name}: {e}\")\n",
    "    \n",
    "    return data['train'], labels['train'], data['val'], labels['val'], data['test'], labels['test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./../../data/external/double_mnist\"\n",
    "\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = load_mnist_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0\n",
    "        image = image.unsqueeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.long).to(device)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MultiMNISTDataset(train_data, train_labels)\n",
    "val_data = MultiMNISTDataset(val_data, val_labels)\n",
    "test_data = MultiMNISTDataset(test_data, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, task='classification', num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.task = task\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        if task == 'classification':\n",
    "            self.fc3 = nn.Linear(64, num_classes)\n",
    "        elif task == 'regression':\n",
    "            self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def _initialize_fc(self, input_shape, device):\n",
    "        dummy_input = torch.zeros(1, *input_shape).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = self._forward_conv(dummy_input)\n",
    "        flattened_size = output.view(-1).shape[0]\n",
    "        self.fc1 = nn.Linear(flattened_size, 128).to(device)\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.fc1 is None:\n",
    "            self._initialize_fc(x.shape[1:], x.device)\n",
    "\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.forward(x)\n",
    "        return y_pred\n",
    "    \n",
    "    def get_accuracy(self, y_pred, y_true):\n",
    "        if self.task == 'classification':\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            return (y_pred == y_true).float().mean()\n",
    "        elif self.task == 'regression':\n",
    "            return F.mse_loss(y_pred, y_true)\n",
    "\n",
    "    \n",
    "    def loss(self, y_pred, y_true):\n",
    "        if self.task == 'classification':\n",
    "            return F.cross_entropy(y_pred, y_true)\n",
    "        elif self.task == 'regression':\n",
    "            return F.mse_loss(y_pred, y_true)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_progress = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        for i, (x, y) in train_progress:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = model.loss(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_progress.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        model.eval()\n",
    "        total_accuracy = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                total_loss += model.loss(y_pred, y).item()\n",
    "                total_accuracy += model.get_accuracy(y_pred, y).item()\n",
    "                \n",
    "            avg_loss = total_loss / len(val_loader)\n",
    "            accuracy = total_accuracy / len(val_loader)\n",
    "            print(f\"Epoch {epoch + 1}, Validation Accuracy: {accuracy*100:.2f}%, Validation Loss: {avg_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 394/394 [00:06<00:00, 60.74it/s, Loss=0.0490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy: 99.10%, Validation Loss: 0.059389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 394/394 [00:06<00:00, 60.39it/s, Loss=0.0190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy: 99.34%, Validation Loss: 0.037673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 394/394 [00:05<00:00, 65.72it/s, Loss=0.1635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy: 99.63%, Validation Loss: 0.040604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 394/394 [00:05<00:00, 68.60it/s, Loss=0.0057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy: 99.50%, Validation Loss: 0.020367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 394/394 [00:05<00:00, 69.68it/s, Loss=0.0043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy: 99.63%, Validation Loss: 0.016056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 394/394 [00:05<00:00, 70.36it/s, Loss=0.0398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy: 99.77%, Validation Loss: 0.011964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 394/394 [00:06<00:00, 64.82it/s, Loss=0.0131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy: 99.73%, Validation Loss: 0.032205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 394/394 [00:05<00:00, 70.79it/s, Loss=0.0074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy: 99.77%, Validation Loss: 0.015004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 394/394 [00:05<00:00, 70.70it/s, Loss=0.0100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy: 99.53%, Validation Loss: 0.020547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 394/394 [00:07<00:00, 51.32it/s, Loss=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy: 99.57%, Validation Loss: 0.029821\n"
     ]
    }
   ],
   "source": [
    "model = CNN(task='classification', num_classes=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train(model, optimizer, train_loader, val_loader, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
