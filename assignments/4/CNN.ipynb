{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Classification Using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(path):\n",
    "    splits = ['train', 'val', 'test']\n",
    "    data = {'train': [], 'val': [], 'test': []}\n",
    "    labels = {'train': [], 'val': [], 'test': []}\n",
    "    for split in splits:\n",
    "        split_path = os.path.join(path, split)\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if (int(label) == 0):\n",
    "                cur_label = 0\n",
    "            else:\n",
    "                cur_label = len(label)\n",
    "            if os.path.isdir(label_path):\n",
    "                for image_name in os.listdir(label_path):\n",
    "                    image_path = os.path.join(label_path, image_name)\n",
    "                    try:\n",
    "                        image = Image.open(image_path).convert('L')\n",
    "                        image_array = np.array(image)\n",
    "                        data[split].append(image_array)\n",
    "                        labels[split].append(cur_label)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {image_name}: {e}\")\n",
    "    \n",
    "    return data['train'], labels['train'], data['val'], labels['val'], data['test'], labels['test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./../../data/external/double_mnist\"\n",
    "\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = load_mnist_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, task = 'classification', transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.task = task\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0\n",
    "        image = image.unsqueeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if (self.task == 'classification'):\n",
    "            label = torch.tensor(label, dtype=torch.long).to(device)\n",
    "        else:\n",
    "            label = torch.tensor(label, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, task='classification', num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.task = task\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        if task == 'classification':\n",
    "            self.fc3 = nn.Linear(64, num_classes)\n",
    "        elif task == 'regression':\n",
    "            self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def _initialize_fc(self, input_shape, device):\n",
    "        dummy_input = torch.zeros(1, *input_shape).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = self._forward_conv(dummy_input)\n",
    "        flattened_size = output.view(-1).shape[0]\n",
    "        self.fc1 = nn.Linear(flattened_size, 128).to(device)\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.fc1 is None:\n",
    "            self._initialize_fc(x.shape[1:], x.device)\n",
    "\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.forward(x)\n",
    "        return y_pred\n",
    "    \n",
    "    def get_accuracy(self, y_pred, y_true):\n",
    "        if self.task == 'classification':\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            return (y_pred == y_true).float().mean()\n",
    "        elif self.task == 'regression':\n",
    "            return F.mse_loss(y_pred, y_true)\n",
    "\n",
    "    \n",
    "    def loss(self, y_pred, y_true):\n",
    "        if self.task == 'classification':\n",
    "            return F.cross_entropy(y_pred, y_true)\n",
    "        elif self.task == 'regression':\n",
    "            return F.mse_loss(y_pred, y_true)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_progress = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        for i, (x, y) in train_progress:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = model.loss(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_progress.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        model.eval()\n",
    "        total_accuracy = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                total_loss += model.loss(y_pred, y).item()\n",
    "                total_accuracy += model.get_accuracy(y_pred, y).item()\n",
    "                \n",
    "            avg_loss = total_loss / len(val_loader)\n",
    "            accuracy = total_accuracy / len(val_loader)\n",
    "            print(f\"Epoch {epoch + 1}, Validation Accuracy: {accuracy*100:.2f}%, Validation Loss: {avg_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_classification = MultiMNISTDataset(train_data, train_labels)\n",
    "val_data_classification = MultiMNISTDataset(val_data, val_labels)\n",
    "test_data_classification = MultiMNISTDataset(test_data, test_labels)\n",
    "\n",
    "train_loader_classification = DataLoader(train_data_classification, batch_size=32, shuffle=True)\n",
    "val_loader_classification = DataLoader(val_data_classification, batch_size=32, shuffle=False)\n",
    "test_loader_classification = DataLoader(test_data_classification, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 394/394 [00:06<00:00, 56.56it/s, Loss=0.0461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy: 97.98%, Validation Loss: 0.093532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 394/394 [00:05<00:00, 77.75it/s, Loss=0.0415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy: 99.53%, Validation Loss: 0.033938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 394/394 [00:05<00:00, 77.66it/s, Loss=0.1484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy: 99.60%, Validation Loss: 0.036460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 394/394 [00:05<00:00, 76.42it/s, Loss=0.0040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy: 99.31%, Validation Loss: 0.019641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 394/394 [00:05<00:00, 75.32it/s, Loss=0.0229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy: 99.83%, Validation Loss: 0.036251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 394/394 [00:05<00:00, 76.02it/s, Loss=0.0070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy: 99.59%, Validation Loss: 0.025552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 394/394 [00:05<00:00, 75.08it/s, Loss=0.0128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy: 99.87%, Validation Loss: 0.015624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 394/394 [00:05<00:00, 74.82it/s, Loss=0.0235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy: 99.73%, Validation Loss: 0.020732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 394/394 [00:05<00:00, 70.95it/s, Loss=0.2366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy: 99.90%, Validation Loss: 0.011307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 394/394 [00:05<00:00, 74.58it/s, Loss=0.0429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy: 99.27%, Validation Loss: 0.024547\n"
     ]
    }
   ],
   "source": [
    "model = CNN(task='classification', num_classes=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train(model, optimizer, train_loader_classification, val_loader_classification, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_regression = MultiMNISTDataset(train_data, train_labels, task='regression')\n",
    "val_data_regression = MultiMNISTDataset(val_data, val_labels, task='regression')\n",
    "test_data_regression = MultiMNISTDataset(test_data, test_labels, task='regression')\n",
    "\n",
    "train_loader_regression = DataLoader(train_data_regression, batch_size=32, shuffle=True)\n",
    "val_loader_regression = DataLoader(val_data_regression, batch_size=32, shuffle=False)\n",
    "test_loader_regression = DataLoader(test_data_regression, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 394/394 [00:05<00:00, 76.70it/s, Loss=0.0865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy: 6.42%, Validation Loss: 0.064170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 394/394 [00:05<00:00, 71.92it/s, Loss=0.1680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy: 4.17%, Validation Loss: 0.041748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 394/394 [00:05<00:00, 71.77it/s, Loss=0.0286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy: 3.07%, Validation Loss: 0.030660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 394/394 [00:05<00:00, 72.52it/s, Loss=0.0269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy: 3.28%, Validation Loss: 0.032797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 394/394 [00:05<00:00, 71.26it/s, Loss=0.0353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy: 2.97%, Validation Loss: 0.029664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 394/394 [00:05<00:00, 71.81it/s, Loss=0.1585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy: 2.08%, Validation Loss: 0.020805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 394/394 [00:05<00:00, 70.92it/s, Loss=0.0217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy: 2.04%, Validation Loss: 0.020432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 394/394 [00:05<00:00, 70.87it/s, Loss=0.0168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy: 2.16%, Validation Loss: 0.021649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 394/394 [00:05<00:00, 66.65it/s, Loss=0.0188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy: 2.49%, Validation Loss: 0.024943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 394/394 [00:05<00:00, 75.29it/s, Loss=0.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy: 2.24%, Validation Loss: 0.022412\n"
     ]
    }
   ],
   "source": [
    "model = CNN(task='regression').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train(model, optimizer, train_loader_regression, val_loader_regression, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
